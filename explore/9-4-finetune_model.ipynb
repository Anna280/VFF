{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon, Point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_data = pd.read_csv(\"/Users/annadaugaard/Desktop/VFF/VFF_analytics_src/data/03_model_data/test_for_streamit.csv\")\n",
    "gps_data=  pd.read_csv(\"/Users/annadaugaard/Desktop/VFF/preprocessed_data_for_decision_making.csv\", index_col=0)\n",
    "gps_data_home = gps_data[gps_data[\"Team\"]== \"home\"]\n",
    "# Step 1: subset pass_data to home team only\n",
    "pass_data_home = pass_data[pass_data[\"Team\"] == \"home\"].reset_index(drop=True)\n",
    "pass_data_home = pass_data_home[pass_data_home[\"uncertainty\"] < 2].reset_index(drop=True)\n",
    "# Columns to keep from gps_data\n",
    "gps_columns = [\"time\", \"player_id\", \"player_num\", \"x\", \"y\", \"spd\", \"ball_x\",\"ball_y\",\"Team\",\"acceleration\", \"smoothed_acceleration\"]\n",
    "\n",
    "# Prepare an empty DataFrame for extracted data\n",
    "extracted_gps_data = pd.DataFrame(columns=gps_columns + [\"pass_event_id\"])\n",
    "\n",
    "# Steps 2 & 3: Extract GPS data for each pass event\n",
    "for idx, row in pass_data_home.iterrows():\n",
    "    from_player = row[\"From\"]\n",
    "    start_time = row[\"Start Time [s]\"]\n",
    "    end_time = row[\"End Time [s]\"]\n",
    "    \n",
    "    # Extract relevant gps data\n",
    "    gps_subset = gps_data_home[\n",
    "        (gps_data_home[\"player_num\"] == from_player) &\n",
    "        (gps_data_home[\"time\"] >= start_time) &\n",
    "        (gps_data_home[\"time\"] <= end_time)\n",
    "    ][gps_columns].copy()\n",
    "\n",
    "    # Add pass event identifier\n",
    "    gps_subset[\"pass_event_id\"] = idx\n",
    "    \n",
    "    # Concatenate results\n",
    "    extracted_gps_data = pd.concat([extracted_gps_data, gps_subset], ignore_index=True)\n",
    "\n",
    "extracted_gps_data[\"distance_to_ball\"] = np.hypot(\n",
    "    extracted_gps_data[\"x\"] - extracted_gps_data[\"ball_x\"],\n",
    "    extracted_gps_data[\"y\"] - extracted_gps_data[\"ball_y\"]\n",
    ")\n",
    "low_distance = extracted_gps_data[extracted_gps_data[\"distance_to_ball\"] < 2]\n",
    "\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df = low_distance.copy()\n",
    "\n",
    "# Identify chunks by consecutive player_num\n",
    "df['player_chunk'] = (df['player_num'] != df['player_num'].shift()).cumsum()\n",
    "\n",
    "# Get index of max acceleration per chunk\n",
    "max_acceleration_indices = df.groupby('player_chunk')['acceleration'].idxmax() - 10\n",
    "\n",
    "# Initialize a list of zeros with length 2500\n",
    "binary_list = [0] * len(extracted_gps_data)\n",
    "\n",
    "\n",
    "\n",
    "# Set positions from max_acceleration_indices to 1, ensuring indices within bounds\n",
    "for idx in max_acceleration_indices:\n",
    "    if 0 <= idx < len(extracted_gps_data):\n",
    "        binary_list[idx] = 1\n",
    "        \n",
    "\n",
    "# Verify the result (optional)\n",
    "extracted_gps_data[\"decision_making_point\"] = binary_list\n",
    "\n",
    "# Iterate over each row in extracted_gps_data with decision-making points\n",
    "decision_points = extracted_gps_data[extracted_gps_data[\"decision_making_point\"] == 1].reset_index()\n",
    "\n",
    "\n",
    "# Robust overlap area calculation function\n",
    "def calculate_overlap_area(target_x, target_y, x_ball, y_ball, away_players, angle_degrees=28.41389086074131, circle_radius=2):\n",
    "    dx, dy = target_x - x_ball, target_y - y_ball\n",
    "    height = np.hypot(dx, dy)\n",
    "    if height == 0:\n",
    "        return 0.0\n",
    "\n",
    "    trajectory_angle = np.arctan2(dy, dx)\n",
    "    half_angle_radians = np.radians(angle_degrees / 2)\n",
    "    base_width = 2 * height * np.tan(half_angle_radians)\n",
    "\n",
    "    left_x = target_x + (base_width / 2) * np.cos(trajectory_angle + np.pi / 2)\n",
    "    left_y = target_y + (base_width / 2) * np.sin(trajectory_angle + np.pi / 2)\n",
    "    right_x = target_x + (base_width / 2) * np.cos(trajectory_angle - np.pi / 2)\n",
    "    right_y = target_y + (base_width / 2) * np.sin(trajectory_angle - np.pi / 2)\n",
    "\n",
    "    points = [(left_x, left_y), (right_x, right_y), (x_ball, y_ball)]\n",
    "\n",
    "    triangle = Polygon(points)\n",
    "    if not triangle.is_valid or triangle.area == 0:\n",
    "        return 0.0\n",
    "\n",
    "    total_overlap_area = sum(\n",
    "        triangle.intersection(Point(away_x, away_y).buffer(circle_radius)).area\n",
    "        for away_x, away_y in zip(away_players[\"x\"], away_players[\"y\"])\n",
    "    )\n",
    "\n",
    "    return total_overlap_area\n",
    "\n",
    "# Updated custom scoring function with directional boost\n",
    "def custom_score(overlap_area, distance_to_ball, ball_direction_x, alpha=0.21378698795024154, beta=0.04521767482654141, gamma=0.961862342433836):\n",
    "    direction_bonus = gamma if ball_direction_x > 0 else -gamma\n",
    "    penalty = alpha * overlap_area + beta * (-distance_to_ball)\n",
    "    return np.exp(-penalty + direction_bonus)\n",
    "\n",
    "# Placeholder for results\n",
    "results = []\n",
    "\n",
    "\n",
    "for idx, row in decision_points.iterrows():\n",
    "    current_time = row[\"time\"]\n",
    "    current_player_num = row[\"player_num\"]\n",
    "    x_ball, y_ball = row[\"ball_x\"], row[\"ball_y\"]\n",
    "\n",
    "    players_at_time = gps_data[(gps_data[\"time\"] == current_time) & \n",
    "                               (gps_data[\"player_num\"] != current_player_num)]\n",
    "\n",
    "    home_players = players_at_time[players_at_time[\"Team\"] == \"home\"]\n",
    "    away_players = players_at_time[players_at_time[\"Team\"] == \"away\"]\n",
    "\n",
    "    for _, home_player in home_players.iterrows():\n",
    "        \n",
    "        ball_direction_x = x_ball -home_player[\"x\"] \n",
    "\n",
    "        distance_to_ball = np.hypot(home_player[\"x\"] - x_ball, home_player[\"y\"] - y_ball)\n",
    "        \n",
    "       # if distance_to_ball < 15:\n",
    "       #     circle_radius = 2\n",
    "       # elif 15 < distance_to_ball <= 25:\n",
    "       #     circle_radius =3\n",
    "        #else:\n",
    "       #     circle_radius=6\n",
    "        \n",
    "        overlap_area = calculate_overlap_area(\n",
    "                target_x=home_player[\"x\"],\n",
    "                target_y=home_player[\"y\"],\n",
    "                x_ball=x_ball,\n",
    "                y_ball=y_ball,\n",
    "                away_players=away_players,\n",
    "                angle_degrees=28.41389086074131,\n",
    "                circle_radius=2\n",
    "            )\n",
    "        # Using custom scoring with directional boost\n",
    "        score = custom_score(overlap_area, distance_to_ball, ball_direction_x)\n",
    "\n",
    "        results.append({\n",
    "            \"timestamp\": current_time,\n",
    "            \"reference_player_num\": current_player_num,\n",
    "            \"target_player_num\": home_player[\"player_num\"],\n",
    "            \"score\": score,\n",
    "            \"pass_event_id\":row[\"pass_event_id\"]\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Convert to wide format\n",
    "results_df_wide = results_df.pivot_table(\n",
    "    index=['timestamp', \"pass_event_id\",'reference_player_num'],\n",
    "    columns='target_player_num',\n",
    "    values='score'\n",
    ").reset_index()\n",
    "\n",
    "results_df_wide.columns = [\n",
    "    f'score_to_player_{int(col)}' if isinstance(col, (int, float)) else col\n",
    "    for col in results_df_wide.columns\n",
    "]\n",
    "\n",
    "# Select columns containing 'score_to_player'\n",
    "score_columns = [col for col in results_df_wide.columns if 'score_to_player' in col]\n",
    "\n",
    "# Find the max value per row among score columns\n",
    "results_df_wide['max_score'] = results_df_wide[score_columns].max(axis=1)\n",
    "\n",
    "# Find the corresponding player column for each max score\n",
    "results_df_wide['max_score_player'] = results_df_wide[score_columns].idxmax(axis=1)\n",
    "\n",
    "# Display the results\n",
    "print(results_df_wide[['timestamp', 'reference_player_num', 'max_score', 'max_score_player']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_points_2 = decision_points[decision_points[\"player_num\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_points_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge pass data with annotations to only process annotated events\n",
    "pass_data_annotated = pd.merge(decision_points_2, annotations2, on='pass_event_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE BEST MODEL; SIMPLE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Robust overlap area calculation function\n",
    "def calculate_overlap_area(target_x, target_y, x_ball, y_ball, away_players, angle_degrees=28.41389086074131, circle_radius=2):\n",
    "    dx, dy = target_x - x_ball, target_y - y_ball\n",
    "    height = np.hypot(dx, dy)\n",
    "    if height == 0:\n",
    "        return 0.0\n",
    "\n",
    "    trajectory_angle = np.arctan2(dy, dx)\n",
    "    half_angle_radians = np.radians(angle_degrees / 2)\n",
    "    base_width = 2 * height * np.tan(half_angle_radians)\n",
    "\n",
    "    left_x = target_x + (base_width / 2) * np.cos(trajectory_angle + np.pi / 2)\n",
    "    left_y = target_y + (base_width / 2) * np.sin(trajectory_angle + np.pi / 2)\n",
    "    right_x = target_x + (base_width / 2) * np.cos(trajectory_angle - np.pi / 2)\n",
    "    right_y = target_y + (base_width / 2) * np.sin(trajectory_angle - np.pi / 2)\n",
    "\n",
    "    points = [(left_x, left_y), (right_x, right_y), (x_ball, y_ball)]\n",
    "\n",
    "    triangle = Polygon(points)\n",
    "    if not triangle.is_valid or triangle.area == 0:\n",
    "        return 0.0\n",
    "\n",
    "    total_overlap_area = sum(\n",
    "        triangle.intersection(Point(away_x, away_y).buffer(circle_radius)).area\n",
    "        for away_x, away_y in zip(away_players[\"x\"], away_players[\"y\"])\n",
    "    )\n",
    "\n",
    "    return total_overlap_area\n",
    "\n",
    "# Updated custom scoring function with directional boost\n",
    "def custom_score(overlap_area, distance_to_ball, ball_direction_x, alpha=0.21378698795024154, beta=0.04521767482654141, gamma=0.961862342433836):\n",
    "    direction_bonus = gamma if ball_direction_x > 0 else -gamma\n",
    "    penalty = alpha * overlap_area + beta * (-distance_to_ball)\n",
    "    return np.exp(-penalty + direction_bonus)\n",
    "\n",
    "# Placeholder for results\n",
    "results = []\n",
    "\n",
    "# Iterate over each row in extracted_gps_data with decision-making points\n",
    "decision_points = extracted_gps_data[extracted_gps_data[\"decision_making_point\"] == 1].reset_index()\n",
    "\n",
    "for idx, row in decision_points.iterrows():\n",
    "    current_time = row[\"time\"]\n",
    "    current_player_num = row[\"player_num\"]\n",
    "    x_ball, y_ball = row[\"ball_x\"], row[\"ball_y\"]\n",
    "\n",
    "    players_at_time = gps_data[(gps_data[\"time\"] == current_time) & \n",
    "                               (gps_data[\"player_num\"] != current_player_num)]\n",
    "\n",
    "    home_players = players_at_time[players_at_time[\"Team\"] == \"home\"]\n",
    "    away_players = players_at_time[players_at_time[\"Team\"] == \"away\"]\n",
    "\n",
    "    for _, home_player in home_players.iterrows():\n",
    "        \n",
    "        ball_direction_x = x_ball -home_player[\"x\"] \n",
    "\n",
    "        distance_to_ball = np.hypot(home_player[\"x\"] - x_ball, home_player[\"y\"] - y_ball)\n",
    "        \n",
    "       # if distance_to_ball < 15:\n",
    "       #     circle_radius = 2\n",
    "       # elif 15 < distance_to_ball <= 25:\n",
    "       #     circle_radius =3\n",
    "        #else:\n",
    "       #     circle_radius=6\n",
    "        \n",
    "        overlap_area = calculate_overlap_area(\n",
    "                target_x=home_player[\"x\"],\n",
    "                target_y=home_player[\"y\"],\n",
    "                x_ball=x_ball,\n",
    "                y_ball=y_ball,\n",
    "                away_players=away_players,\n",
    "                angle_degrees=28.41389086074131,\n",
    "                circle_radius=2\n",
    "            )\n",
    "        # Using custom scoring with directional boost\n",
    "        score = custom_score(overlap_area, distance_to_ball, ball_direction_x)\n",
    "\n",
    "        results.append({\n",
    "            \"timestamp\": current_time,\n",
    "            \"reference_player_num\": current_player_num,\n",
    "            \"target_player_num\": home_player[\"player_num\"],\n",
    "            \"score\": score,\n",
    "            \"pass_event_id\":row[\"pass_event_id\"]\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Convert to wide format\n",
    "results_df_wide = results_df.pivot_table(\n",
    "    index=['timestamp', \"pass_event_id\",'reference_player_num'],\n",
    "    columns='target_player_num',\n",
    "    values='score'\n",
    ").reset_index()\n",
    "\n",
    "results_df_wide.columns = [\n",
    "    f'score_to_player_{int(col)}' if isinstance(col, (int, float)) else col\n",
    "    for col in results_df_wide.columns\n",
    "]\n",
    "\n",
    "# Select columns containing 'score_to_player'\n",
    "score_columns = [col for col in results_df_wide.columns if 'score_to_player' in col]\n",
    "\n",
    "# Find the max value per row among score columns\n",
    "results_df_wide['max_score'] = results_df_wide[score_columns].max(axis=1)\n",
    "\n",
    "# Find the corresponding player column for each max score\n",
    "results_df_wide['max_score_player'] = results_df_wide[score_columns].idxmax(axis=1)\n",
    "\n",
    "# Display the results\n",
    "print(results_df_wide[['timestamp', 'reference_player_num', 'max_score', 'max_score_player']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHANGEING RADIUS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_points = extracted_gps_data[extracted_gps_data[\"decision_making_point\"] == 1].reset_index()\n",
    "\n",
    "# --- Overlap Area Calculation ---\n",
    "def calculate_overlap_area(target_x, target_y, x_ball, y_ball, away_players, angle_degrees=40, circle_radius=2):\n",
    "    dx, dy = target_x - x_ball, target_y - y_ball\n",
    "    height = np.hypot(dx, dy)\n",
    "    if height == 0:\n",
    "        return 0.0\n",
    "\n",
    "    angle = np.arctan2(dy, dx)\n",
    "    half_angle = np.radians(angle_degrees / 2)\n",
    "    base = 2 * height * np.tan(half_angle)\n",
    "\n",
    "    left = (target_x + (base / 2) * np.cos(angle + np.pi/2),\n",
    "            target_y + (base / 2) * np.sin(angle + np.pi/2))\n",
    "    right = (target_x + (base / 2) * np.cos(angle - np.pi/2),\n",
    "             target_y + (base / 2) * np.sin(angle - np.pi/2))\n",
    "\n",
    "    triangle = Polygon([left, right, (x_ball, y_ball)])\n",
    "    if not triangle.is_valid or triangle.area == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return sum(\n",
    "        triangle.intersection(Point(x, y).buffer(circle_radius)).area\n",
    "        for x, y in zip(away_players[\"x\"], away_players[\"y\"])\n",
    "    )\n",
    "\n",
    "# --- Custom Scoring ---\n",
    "def custom_score(overlap_area, distance_to_ball, ball_direction_x, alpha=0.263, beta=0.035, gamma=0.671):\n",
    "    direction_bonus = gamma if ball_direction_x > 0 else -gamma\n",
    "    penalty = alpha * overlap_area + beta * (-distance_to_ball)\n",
    "    return np.exp(-penalty + direction_bonus)\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, row in decision_points.iterrows():\n",
    "    current_time = row[\"time\"]\n",
    "    current_player_num = row[\"player_num\"]\n",
    "    x_ball, y_ball = row[\"ball_x\"], row[\"ball_y\"]\n",
    "\n",
    "    players_at_time = gps_data[(gps_data[\"time\"] == current_time) & \n",
    "                                (gps_data[\"player_num\"] != current_player_num)]\n",
    "    home_players = players_at_time[players_at_time[\"Team\"] == \"home\"]\n",
    "    away_players = players_at_time[players_at_time[\"Team\"] == \"away\"]\n",
    "\n",
    "    for _, home_player in home_players.iterrows():\n",
    "        ball_direction_x = x_ball - home_player[\"x\"]\n",
    "        distance_to_ball = np.hypot(home_player[\"x\"] - x_ball, home_player[\"y\"] - y_ball)\n",
    "\n",
    "        if distance_to_ball < 15:\n",
    "            circle_radius = 2\n",
    "        elif distance_to_ball <= 25:\n",
    "            circle_radius = 3\n",
    "        else:\n",
    "            circle_radius = 6\n",
    "\n",
    "        overlap_area = calculate_overlap_area(\n",
    "            target_x=home_player[\"x\"],\n",
    "            target_y=home_player[\"y\"],\n",
    "            x_ball=x_ball,\n",
    "            y_ball=y_ball,\n",
    "            away_players=away_players,\n",
    "            angle_degrees=22.73,\n",
    "            circle_radius=circle_radius\n",
    "        )\n",
    "\n",
    "        score = custom_score(overlap_area, distance_to_ball, ball_direction_x)\n",
    "\n",
    "        results.append({\n",
    "            \"timestamp\": current_time,\n",
    "            \"reference_player_num\": current_player_num,\n",
    "            \"target_player_num\": home_player[\"player_num\"],\n",
    "            \"score\": score,\n",
    "            \"pass_event_id\": row[\"pass_event_id\"]\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df_wide = results_df.pivot_table(\n",
    "    index=['timestamp', \"pass_event_id\", 'reference_player_num'],\n",
    "    columns='target_player_num',\n",
    "    values='score'\n",
    ").reset_index()\n",
    "\n",
    "results_df_wide.columns = [\n",
    "    f'score_to_player_{int(col)}' if isinstance(col, (int, float)) else col\n",
    "    for col in results_df_wide.columns\n",
    "]\n",
    "\n",
    "score_columns = [col for col in results_df_wide.columns if 'score_to_player' in col]\n",
    "results_df_wide['max_score'] = results_df_wide[score_columns].max(axis=1)\n",
    "results_df_wide['max_score_player'] = results_df_wide[score_columns].idxmax(axis=1)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WEIGHTED TRIANGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Triangle Density ---\n",
    "def triangle_density_weighted(px, py, a, b, c):\n",
    "    local_y = py / 3\n",
    "    return np.exp(-((local_y - 0.15) ** 2) * 10) + np.exp(-((local_y - 0.85) ** 2) * 10)\n",
    "\n",
    "# --- Weighted Overlap ---\n",
    "def calculate_weighted_overlap_area(target_x, target_y, x_ball, y_ball, away_players, angle_degrees=40, circle_radius=2):\n",
    "    dx, dy = target_x - x_ball, target_y - y_ball\n",
    "    height = np.hypot(dx, dy)\n",
    "    if height == 0:\n",
    "        return 0.0\n",
    "\n",
    "    angle = np.arctan2(dy, dx)\n",
    "    half_angle = np.radians(angle_degrees / 2)\n",
    "    base = 2 * height * np.tan(half_angle)\n",
    "\n",
    "    left = (target_x + (base / 2) * np.cos(angle + np.pi / 2),\n",
    "            target_y + (base / 2) * np.sin(angle + np.pi / 2))\n",
    "    right = (target_x + (base / 2) * np.cos(angle - np.pi / 2),\n",
    "             target_y + (base / 2) * np.sin(angle - np.pi / 2))\n",
    "\n",
    "    triangle = Polygon([left, right, (x_ball, y_ball)])\n",
    "    if not triangle.is_valid or triangle.area == 0:\n",
    "        return 0.0\n",
    "\n",
    "    total_weighted_area = 0\n",
    "    for x, y in zip(away_players['x'], away_players['y']):\n",
    "        point = Point(x, y).buffer(circle_radius)\n",
    "        intersection = triangle.intersection(point)\n",
    "        if not intersection.is_empty:\n",
    "            rel_x, rel_y = x - x_ball, y - y_ball\n",
    "            if height > 15:\n",
    "                density = triangle_density_weighted(rel_x, rel_y, np.array([0, 0]), np.array([-1.5, 3]), np.array([1.5, 3]))\n",
    "                total_weighted_area += intersection.area * density\n",
    "            else:\n",
    "                total_weighted_area += intersection.area \n",
    "\n",
    "    return total_weighted_area\n",
    "\n",
    "# --- Scoring ---\n",
    "def custom_score(overlap_area, distance_to_ball, ball_direction_x, alpha=0.159, beta=0.047, gamma=0.455):\n",
    "    direction_bonus = gamma if ball_direction_x > 0 else -gamma\n",
    "    penalty = alpha * overlap_area + beta * (-distance_to_ball)\n",
    "    return np.exp(-penalty + direction_bonus)\n",
    "\n",
    "# --- Filter Decision Points ---\n",
    "decision_points = extracted_gps_data[extracted_gps_data[\"decision_making_point\"] == 1].reset_index()\n",
    "#decision_points = decision_points[decision_points[\"player_num\"] == 24]\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, row in decision_points.iterrows():\n",
    "    current_time = row[\"time\"]\n",
    "    current_player_num = row[\"player_num\"]\n",
    "    x_ball, y_ball = row[\"ball_x\"], row[\"ball_y\"]\n",
    "\n",
    "    players_at_time = gps_data[(gps_data[\"time\"] == current_time) & \n",
    "                                (gps_data[\"player_num\"] != current_player_num)]\n",
    "    home_players = players_at_time[players_at_time[\"Team\"] == \"home\"]\n",
    "    away_players = players_at_time[players_at_time[\"Team\"] == \"away\"]\n",
    "\n",
    "\n",
    "    for _, home_player in home_players.iterrows():\n",
    "        ball_direction_x = x_ball - home_player[\"x\"]\n",
    "        distance_to_ball = np.hypot(home_player[\"x\"] - x_ball, home_player[\"y\"] - y_ball)\n",
    "\n",
    "        overlap_area = calculate_weighted_overlap_area(\n",
    "            target_x=home_player[\"x\"],\n",
    "            target_y=home_player[\"y\"],\n",
    "            x_ball=x_ball,\n",
    "            y_ball=y_ball,\n",
    "            away_players=away_players,\n",
    "            angle_degrees=38.46,\n",
    "            circle_radius=2\n",
    "        )\n",
    "\n",
    "        score = custom_score(overlap_area, distance_to_ball, ball_direction_x)\n",
    "\n",
    "        results.append({\n",
    "            \"timestamp\": current_time,\n",
    "            \"reference_player_num\": current_player_num,\n",
    "            \"target_player_num\": home_player[\"player_num\"],\n",
    "            \"score\": score,\n",
    "            \"pass_event_id\": row[\"pass_event_id\"]\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df_wide = results_df.pivot_table(\n",
    "    index=['timestamp', \"pass_event_id\", 'reference_player_num'],\n",
    "    columns='target_player_num',\n",
    "    values='score'\n",
    ").reset_index()\n",
    "\n",
    "results_df_wide.columns = [\n",
    "    f'score_to_player_{int(col)}' if isinstance(col, (int, float)) else col\n",
    "    for col in results_df_wide.columns\n",
    "]\n",
    "\n",
    "score_columns = [col for col in results_df_wide.columns if 'score_to_player' in col]\n",
    "results_df_wide['max_score'] = results_df_wide[score_columns].max(axis=1)\n",
    "results_df_wide['max_score_player'] = results_df_wide[score_columns].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision_points = extracted_gps_data[extracted_gps_data[\"decision_making_point\"] == 1].reset_index()\n",
    "results_df_wide['max_score_player'] = results_df_wide['max_score_player'].str.extract('score_to_player_(\\d+)').astype(int)\n",
    "\n",
    "#decision_points_24 = decision_points[decision_points[\"player_num\"]==24]\n",
    "#decision_points_24.to_csv(\"deciision_points_24.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE RESULTS PLAYER 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "only_24 = results_df_wide[results_df_wide[\"reference_player_num\"] == 24]\n",
    "only_24.reset_index(drop=True, inplace=True)\n",
    "only_24.index = only_24.index + 1\n",
    "df_filtered = only_24.drop(index=[3,6,17,20,25,30,34,40,42,44,45,47])\n",
    "df_filtered.index = df_filtered.index.astype(int)\n",
    "\n",
    "annotations = pd.read_csv(\"/Users/annadaugaard/Desktop/VFF/explore/spiller_24_renskrevet.csv\",sep=\";\")\n",
    "annotations[\"player_num\"] = annotations[\"player_num\"].astype(int)\n",
    "# Merge with ground truth using to_x == player_num\n",
    "\n",
    "merged_df = annotations.merge(df_filtered, left_on='Picture_id', right_index=True)\n",
    "\n",
    "# Filter rows where player_num matches to_x\n",
    "matching_rows2 = merged_df[merged_df[\"max_score_player\"] == merged_df[\"player_num\"]]\n",
    "accuracy = len(matching_rows2)/len(annotations[\"Picture_id\"].unique())\n",
    "\n",
    "\n",
    "# Merge to identify matched entries by Picture_id and Type\n",
    "merged = pd.merge(annotations, matching_rows2, on=[\"Picture_id\", \"Type\"], suffixes=('_ann', '_pred'))\n",
    "\n",
    "# Count occurrences per Type\n",
    "annotation_counts_model = annotations[\"Type\"].value_counts().rename(\"Annotated\")\n",
    "prediction_counts_model = merged[\"Type\"].value_counts().rename(\"Model Predicted\")\n",
    "\n",
    "# Combine into one DataFrame for plotting\n",
    "comparison_df_model_24 = pd.concat([annotation_counts_model, prediction_counts_model], axis=1).fillna(0)\n",
    "\n",
    "\n",
    "comparison_df_model_24[\"Accuracy (%)\"] = (comparison_df_model_24[\"Model Predicted\"] / comparison_df_model_24[\"Annotated\"]) * 100\n",
    "\n",
    "# Modify the x-axis labels to include the percentage\n",
    "new_labels = [f\"{type_}\\n{acc:.1f}%\" for type_, acc in zip(comparison_df_model_24.index, comparison_df_model_24[\"Accuracy (%)\"])]\n",
    "\n",
    "# Calculate overall accuracy\n",
    "total_annotated = comparison_df_model_24[\"Annotated\"].sum()\n",
    "total_predicted = comparison_df_model_24[\"Model Predicted\"].sum()\n",
    "\n",
    "overall_accuracy =  len(matching_rows2)/len(annotations[\"Picture_id\"].unique()) * 100\n",
    "\n",
    "# Plot with new x-axis labels and overall accuracy as xlabel\n",
    "ax = comparison_df_model_24[[\"Annotated\", \"Model Predicted\"]].plot(\n",
    "    kind=\"bar\", figsize=(10, 6), color=[\"skyblue\", \"salmon\"]\n",
    ")\n",
    "ax.set_title(\"Comparison of Annotated vs Model Predicted Counts by Type player 24\")\n",
    "ax.set_xlabel(f\"Type (Overall Accuracy: {overall_accuracy:.1f}%)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xticklabels(new_labels, rotation=0)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(annotations[\"Picture_id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE RESULTS PLAYER 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_subset = merged_df[['player_num','Type', 'preference', 'timestamp', 'reference_player_num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_subset.to_csv(\"player_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "annotations = pd.read_csv(\"spiller_2_renskrevet.csv\",sep=\";\")\n",
    "annotations = annotations.drop(index=5)\n",
    "only_2 = results_df_wide[results_df_wide[\"reference_player_num\"] == 2]\n",
    "only_2.reset_index(drop=True, inplace=True)\n",
    "only_2.index = only_2.index + 1\n",
    "df_2 = only_2.drop(index=[3,5,7,17,25,30,24])\n",
    "annotations = pd.read_csv(\"spiller_2_renskrevet.csv\",sep=\";\")\n",
    "annotations = annotations.drop(index=[5,12])\n",
    "annotations[\"player_num\"] = annotations[\"player_num\"].astype(int)\n",
    "# Merge with ground truth using to_x == player_num\n",
    "merged_df = annotations.merge(df_2, left_on='Picture_id', right_index=True)\n",
    "# Filter rows where player_num matches to_x\n",
    "matching_rows2 = merged_df[merged_df[\"max_score_player\"] == merged_df[\"player_num\"]]\n",
    "len(matching_rows2)/len(annotations[\"Picture_id\"].unique())\n",
    "\n",
    "# Filter out NaN values in annotations\n",
    "annotations = annotations.dropna(subset=[\"Type\"])\n",
    "\n",
    "# Merge to identify matched entries by Picture_id and Type\n",
    "merged = pd.merge(annotations, matching_rows2, on=[\"Picture_id\", \"Type\"], suffixes=('_ann', '_pred'))\n",
    "\n",
    "# Count occurrences per Type\n",
    "annotation_counts = annotations[\"Type\"].value_counts().rename(\"Annotated\")\n",
    "prediction_counts = merged[\"Type\"].value_counts().rename(\"Model Predicted\")\n",
    "\n",
    "# Combine into one DataFrame for plotting\n",
    "comparison_df_player_2_model= pd.concat([annotation_counts, prediction_counts], axis=1).fillna(0)\n",
    "\n",
    "comparison_df_player_2_model[\"Accuracy (%)\"] = (comparison_df_player_2_model[\"Model Predicted\"] / comparison_df_player_2_model[\"Annotated\"]) * 100\n",
    "\n",
    "# Modify the x-axis labels to include the percentage\n",
    "new_labels = [f\"{type_}\\n{acc:.1f}%\" for type_, acc in zip(comparison_df_player_2_model.index, comparison_df_player_2_model[\"Accuracy (%)\"])]\n",
    "\n",
    "# Calculate overall accuracy\n",
    "total_annotated = comparison_df_player_2_model[\"Annotated\"].sum()\n",
    "total_predicted = comparison_df_player_2_model[\"Model Predicted\"].sum()\n",
    "overall_accuracy = (total_predicted / total_annotated) * 100\n",
    "\n",
    "# Plot with new x-axis labels and overall accuracy as xlabel\n",
    "ax = comparison_df_player_2_decision[[\"Annotated\", \"Model Predicted\"]].plot(\n",
    "    kind=\"bar\", figsize=(10, 6), color=[\"skyblue\", \"salmon\"]\n",
    ")\n",
    "ax.set_title(\"Comparison of Annotated vs Model Predicted Counts by Type player 2\")\n",
    "ax.set_xlabel(f\"Type (Overall Accuracy: {overall_accuracy:.1f}%)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xticklabels(new_labels, rotation=0)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matching_rows2)/len(annotations[\"Picture_id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALCULATING PLAYER 2 ACTUAL DECISION PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_points_2 = decision_points[decision_points[\"player_num\"]==2]\n",
    "decision_points_2.reset_index(drop=True, inplace=True)\n",
    "decision_points_2.index = decision_points_2.index + 1\n",
    "df_filtered_player2 = decision_points_2.drop(index=[3,5,7,17,25,30,34])\n",
    "\n",
    "real_player2_events = pd.read_csv(\"/Users/annadaugaard/Desktop/VFF/deployment/tracking/test_for_streamit.csv\")\n",
    "pass_data_home = real_player2_events[real_player2_events[\"Team\"] == \"home\"].reset_index(drop=True)\n",
    "pass_data_home = pass_data_home[pass_data_home[\"uncertainty\"] < 2].reset_index(drop=True)\n",
    "\n",
    "annotations2 = pd.read_csv(\"spiller_2_renskrevet.csv\",sep=\";\")\n",
    "annotations2 = annotations2.drop(index=[12,5])\n",
    "annotations2[\"player_num\"] = annotations2[\"player_num\"].astype(int)\n",
    "\n",
    "merged_df = df_filtered_player2.merge(pass_data_home, left_on='pass_event_id', right_index=True)\n",
    "merged_df = merged_df.drop(merged_df.columns[0], axis = 1)\n",
    "merged_df[\"Picture_id\"] = merged_df.index\n",
    "final_df = annotations2.merge(merged_df, on=\"Picture_id\", how=\"left\")\n",
    "matching_rows2 = final_df[final_df[\"player_num_x\"] == final_df[\"To\"]]\n",
    "accuracy = len(matching_rows2)/len(annotations2[\"Picture_id\"])\n",
    "\n",
    "\n",
    "# Filter out NaN values in annotations\n",
    "#annotations = annotations2.dropna(subset=[\"Type\"])\n",
    "\n",
    "# Merge to identify matched entries by Picture_id and Type\n",
    "merged = pd.merge(annotations2, matching_rows2, on=[\"Picture_id\", \"Type\"], suffixes=('_ann', '_pred'))\n",
    "\n",
    "# Count occurrences per Type\n",
    "annotation_counts = annotations2[\"Type\"].value_counts().rename(\"Annotated\")\n",
    "prediction_counts = matching_rows2[\"Type\"].value_counts().rename(\"Model Predicted\")\n",
    "\n",
    "# Combine into one DataFrame for plotting\n",
    "comparison_df_player_2_decision = pd.concat([annotation_counts, prediction_counts], axis=1).fillna(0)\n",
    "\n",
    "\n",
    "comparison_df_player_2_decision[\"Accuracy (%)\"] = (comparison_df_player_2_decision[\"Model Predicted\"] / comparison_df_player_2_decision[\"Annotated\"]) * 100\n",
    "\n",
    "# Modify the x-axis labels to include the percentage\n",
    "new_labels = [f\"{type_}\\n{acc:.1f}%\" for type_, acc in zip(comparison_df_player_2_decision.index, comparison_df_player_2_decision[\"Accuracy (%)\"])]\n",
    "\n",
    "# Calculate overall accuracy\n",
    "total_annotated = comparison_df_player_2_decision[\"Annotated\"].sum()\n",
    "total_predicted = comparison_df_player_2_decision[\"Model Predicted\"].sum()\n",
    "overall_accuracy = len(matching_rows2)/len(annotations2[\"Picture_id\"])* 100\n",
    "\n",
    "# Plot with new x-axis labels and overall accuracy as xlabel\n",
    "ax = comparison_df_player_2_decision[[\"Annotated\", \"Model Predicted\"]].plot(\n",
    "    kind=\"bar\", figsize=(10, 6), color=[\"skyblue\", \"salmon\"]\n",
    ")\n",
    "ax.set_title(\"Comparison of Annotated vs Actual Decisions by Type player 2\")\n",
    "ax.set_xlabel(f\"Type (Overall Accuracy: {overall_accuracy:.1f}%)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xticklabels(new_labels, rotation=0)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLAYER 24 ACTUAL DECISION PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_points_24 = decision_points[decision_points[\"player_num\"]==24]\n",
    "decision_points_24.reset_index(drop=True, inplace=True)\n",
    "decision_points_24.index = decision_points_24.index + 1\n",
    "df_24 = decision_points_24.drop(index=[3,6,17,20,25,30,34,40,42,44,45,47])\n",
    "\n",
    "real_player24_events = pd.read_csv(\"/Users/annadaugaard/Desktop/VFF/deployment/tracking/test_for_streamit.csv\")\n",
    "pass_data_home = real_player24_events[real_player24_events[\"Team\"] == \"home\"].reset_index(drop=True)\n",
    "pass_data_home = pass_data_home[pass_data_home[\"uncertainty\"] < 2].reset_index(drop=True)\n",
    "annotations24= pd.read_csv(\"spiller_24_renskrevet.csv\",sep=\";\")\n",
    "annotations24[\"player_num\"] = annotations24[\"player_num\"].astype(int)\n",
    "merged_df_24 = df_24.merge(pass_data_home, left_on='pass_event_id', right_index=True)\n",
    "merged_df_24 = merged_df_24.drop(merged_df_24.columns[0], axis = 1)\n",
    "\n",
    "merged_df_24[\"Picture_id\"] = merged_df_24.index\n",
    "final_df_24 = annotations24.merge(merged_df_24, on=\"Picture_id\", how=\"left\")\n",
    "matching_rows24 = final_df_24[final_df_24[\"player_num_x\"] == final_df_24[\"To\"]]\n",
    "accuracy_24 = len(matching_rows24)/len(annotations24[\"Picture_id\"].unique())\n",
    "# Merge to identify matched entries by Picture_id and Type\n",
    "merged = pd.merge(annotations24, matching_rows24, on=[\"Picture_id\", \"Type\"], suffixes=('_ann', '_pred'))\n",
    "\n",
    "# Count occurrences per Type\n",
    "annotation_counts_decision = annotations24[\"Type\"].value_counts().rename(\"Annotated\")\n",
    "prediction_counts_decision = matching_rows24[\"Type\"].value_counts().rename(\"Model Predicted\")\n",
    "\n",
    "# Combine into one DataFrame for plotting\n",
    "comparison_df_decision_24 = pd.concat([annotation_counts_decision, prediction_counts_decision], axis=1).fillna(0)\n",
    "\n",
    "comparison_df_decision_24[\"Accuracy (%)\"] = (comparison_df_decision_24[\"Model Predicted\"] / comparison_df_decision_24[\"Annotated\"]) * 100\n",
    "\n",
    "# Modify the x-axis labels to include the percentage\n",
    "new_labels = [f\"{type_}\\n{acc:.1f}%\" for type_, acc in zip(comparison_df_decision_24.index, comparison_df_decision_24[\"Accuracy (%)\"])]\n",
    "\n",
    "# Calculate overall accuracy\n",
    "total_annotated = comparison_df_decision_24[\"Annotated\"].sum()\n",
    "total_predicted = comparison_df_decision_24[\"Model Predicted\"].sum()\n",
    "overall_accuracy =  len(matching_rows24)/len(annotations24[\"Picture_id\"].unique())*100\n",
    "\n",
    "# Plot with new x-axis labels and overall accuracy as xlabel\n",
    "ax = comparison_df_decision_24[[\"Annotated\", \"Model Predicted\"]].plot(\n",
    "    kind=\"bar\", figsize=(10, 6), color=[\"skyblue\", \"salmon\"]\n",
    ")\n",
    "ax.set_title(\"Comparison of Annotated vs Actual decisions by Type player 24\")\n",
    "ax.set_xlabel(f\"Type (Overall Accuracy: {overall_accuracy:.1f}%)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xticklabels(new_labels, rotation=0)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPAIRSON OF MODEL AND PLAYERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "accuracy_df = pd.DataFrame({\n",
    "    \"Model Prediction Accuracy\": comparison_df_model_24[\"Accuracy (%)\"],\n",
    "    \"Player Decision Accuracy\": comparison_df_decision_24[\"Accuracy (%)\"]\n",
    "})\n",
    "colors = [\"#F79256\", \"#006a5d\"]\n",
    "ax = accuracy_df.plot(kind='bar', figsize=(10, 6),color=colors)\n",
    "ax.set_title(\"Model 3: Accuracy Comparison Relative to Annotations Player 24\")\n",
    "ax.set_xlabel(\"Pass Category\")\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0, 100)\n",
    "#plt.grid(axis=\"y\")\n",
    "\n",
    "# Add percentage labels on top of bars\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt=' %.1f%%', label_type='edge', padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counts_df = pd.DataFrame({\n",
    "    \"Annotated\": comparison_df_decision_24[\"Annotated\"],  # same for both\n",
    "    \"Model\": comparison_df_model_24[\"Model Predicted\"],\n",
    "    \"Player\": comparison_df_decision_24[\"Model Predicted\"]\n",
    "})\n",
    "\n",
    "colors = [\"#c7c7c7\",\"#F79256\", \"#006a5d\"]\n",
    "# Plotting\n",
    "ax = counts_df.plot(kind='bar', figsize=(10, 6), color=colors)\n",
    "ax.set_title(\"Model 3: Count Comparison between Annotations, Model Prediction and Player 24 Decisions\")\n",
    "ax.set_xlabel(\"Pass Category\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.xticks(rotation=0)\n",
    "#plt.grid(axis=\"y\")\n",
    "\n",
    "# Add count labels on top of bars\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.0f', label_type='edge', padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "colors = {\n",
    "    \"Model Prediction Accuracy\": \"#1f77b4\",  # blue\n",
    "    \"Player Decision Accuracy\": \"#ff7f0e\",   # orange\n",
    "    \"Annotated\": \"#c7c7c7\",                 # grey\n",
    "    \"Model\": \"#1f77b4\",                     # blue\n",
    "    \"Player\": \"#ff7f0e\"                     # orange\n",
    "}\n",
    "accuracy_df = pd.DataFrame({\n",
    "    \"Model Prediction Accuracy\": comparison_df_model_24[\"Accuracy (%)\"],\n",
    "    \"Player Decision Accuracy\": comparison_df_decision_24[\"Accuracy (%)\"]\n",
    "})\n",
    "\n",
    "accuracy_df.plot(kind='bar', ax=axes[0], color=[colors[\"Model Prediction Accuracy\"], colors[\"Player Decision Accuracy\"]])\n",
    "axes[0].set_title(\"Hit-Percentage per Type: Model vs Player 24\")\n",
    "axes[0].set_xlabel(\"Type\")\n",
    "axes[0].set_ylabel(\"Accuracy (%)\")\n",
    "axes[0].set_ylim(0, 100)\n",
    "#axes[0].grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "axes[0].legend(loc=\"upper right\", frameon=False)\n",
    "\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container, fmt='  %.1f%%', label_type='edge', padding=3)\n",
    "\n",
    "# Count plot\n",
    "counts_df = pd.DataFrame({\n",
    "    \"Annotated\": comparison_df_decision_24[\"Annotated\"],\n",
    "    \"Model\": comparison_df_model_24[\"Model Predicted\"],\n",
    "    \"Player\": comparison_df_decision_24[\"Model Predicted\"]\n",
    "})\n",
    "counts_df.plot(kind='bar', ax=axes[1], color=[colors[\"Annotated\"], colors[\"Model\"], colors[\"Player\"]])\n",
    "axes[1].set_title(\"Count per Type: Annotated vs Model vs Player\")\n",
    "axes[1].set_xlabel(\"Type\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "#axes[1].grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "axes[1].legend(loc=\"upper right\", frameon=False)\n",
    "\n",
    "for container in axes[1].containers:\n",
    "    axes[1].bar_label(container, fmt='%.0f', label_type='edge', padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy_df = pd.DataFrame({\n",
    "    \"Model Prediction Accuracy\": comparison_df_player_2_model[\"Accuracy (%)\"],\n",
    "    \"Player Decision Accuracy\": comparison_df_player_2_decision[\"Accuracy (%)\"]\n",
    "})\n",
    "colors = [\"#F79256\", \"#006a5d\"]\n",
    "ax = accuracy_df.plot(kind='bar', figsize=(10, 6),color=colors)\n",
    "ax.set_title(\"Model 1: Accuracy Comparison Relative to Annotations Player 2\")\n",
    "ax.set_xlabel(\"Pass Category\")\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0, 100)\n",
    "#plt.grid(axis=\"y\")\n",
    "\n",
    "# Add percentage labels on top of bars\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt=' %.1f%%', label_type='edge', padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df_player_2_decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counts_df = pd.DataFrame({\n",
    "    \"Annotated\": comparison_df_player_2_decision[\"Annotated\"],  # same for both\n",
    "    \"Model\": comparison_df_player_2_model[\"Model Predicted\"],\n",
    "    \"Player\": comparison_df_player_2_decision[\"Model Predicted\"]\n",
    "})\n",
    "colors = [\"#c7c7c7\",\"#F79256\", \"#006a5d\"]\n",
    "# Plotting\n",
    "ax = counts_df.plot(kind='bar', figsize=(10, 6), color=colors)\n",
    "ax.set_title(\"Model 1: Count Comparison between Annotations, Model Prediction and Player 2 Decisions\")\n",
    "ax.set_xlabel(\"Pass Category\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.xticks(rotation=0)\n",
    "#plt.grid(axis=\"y\")\n",
    "\n",
    "# Add count labels on top of bars\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.0f', label_type='edge', padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "accuracy_df = pd.DataFrame({\n",
    "    \"Model Prediction Accuracy\": comparison_df_player_2_model[\"Accuracy (%)\"],\n",
    "    \"Player Decision Accuracy\": comparison_df_player_2_decision[\"Accuracy (%)\"]\n",
    "})\n",
    "\n",
    "\n",
    "colors = {\n",
    "    \"Model Prediction Accuracy\": \"#1f77b4\",  # blue\n",
    "    \"Player Decision Accuracy\": \"#ff7f0e\",   # orange\n",
    "    \"Annotated\": \"#c7c7c7\",                 # grey\n",
    "    \"Model\": \"#1f77b4\",                     # blue\n",
    "    \"Player\": \"#ff7f0e\"                     # orange\n",
    "}\n",
    "\n",
    "\n",
    "accuracy_df.plot(kind='bar', ax=axes[0], color=[colors[\"Model Prediction Accuracy\"], colors[\"Player Decision Accuracy\"]])\n",
    "axes[0].set_title(\"Hit-Percentage per Type: Model vs Player 24\")\n",
    "axes[0].set_xlabel(\"Type\")\n",
    "axes[0].set_ylabel(\"Accuracy (%)\")\n",
    "axes[0].set_ylim(0, 100)\n",
    "#axes[0].grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "axes[0].legend(loc=\"upper right\", frameon=False)\n",
    "\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container, fmt='  %.1f%%', label_type='edge', padding=3)\n",
    "\n",
    "# Count plot\n",
    "counts_df = pd.DataFrame({\n",
    "    \"Annotated\": comparison_df_player_2_decision[\"Annotated\"],\n",
    "    \"Model\": comparison_df_player_2_model[\"Model Predicted\"],\n",
    "    \"Player\": comparison_df_player_2_decision[\"Model Predicted\"]\n",
    "})\n",
    "counts_df.plot(kind='bar', ax=axes[1], color=[colors[\"Annotated\"], colors[\"Model\"], colors[\"Player\"]])\n",
    "axes[1].set_title(\"Count per Type: Annotated vs Model vs Player\")\n",
    "axes[1].set_xlabel(\"Type\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "#axes[1].grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "axes[1].legend(loc=\"upper right\", frameon=False)\n",
    "\n",
    "for container in axes[1].containers:\n",
    "    axes[1].bar_label(container, fmt='%.0f', label_type='edge', padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonVFF",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
